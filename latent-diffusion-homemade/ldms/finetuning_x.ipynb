{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fall/bin/miniconda3/envs/ldm_py311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import model_loader\n",
    "import pipeline\n",
    "from PIL import Image\n",
    "from transformers import CLIPTokenizer\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "import torch\n",
    "from torch.optim import  SGD\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from clip import CLIP\n",
    "from ddpm import DDPMSampler\n",
    "from pipeline import generate, get_time_embedding\n",
    "\n",
    "from pipeline import preprocess_image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1 on GPUs [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# GPU 설정\n",
    "device_ids = [1, 2, 3, 4, 5]  \n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(f\"Using device: {device} on GPUs {device_ids}\")\n",
    "\n",
    "device = f\"cuda:{device_ids[0]}\"  # 첫 번째 GPU를 기본 device로 설정\n",
    "print(f\"Using device: {device} on GPUs {device_ids}\")\n",
    "\n",
    "# 토크나이저 및 모델 로드\n",
    "tokenizer = CLIPTokenizer(\"../data/vocab.json\", merges_file=\"../data/merges.txt\")\n",
    "model_file = \"../data/v1-5-pruned-emaonly.ckpt\"\n",
    "models = model_loader.preload_models_from_standard_weights(model_file, device)\n",
    "\n",
    "# Diffusion 모델 병렬화 설정\n",
    "model = models[\"diffusion\"]\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=device_ids)  # 모델 병렬화\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PairedImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.pairs = self._make_pairs()\n",
    "\n",
    "    def _make_pairs(self):\n",
    "        pairs = []\n",
    "        valid_extensions = {\".jpg\", \".jpeg\", \".png\"}  # 유효한 이미지 확장자\n",
    "\n",
    "        # 각 폴더를 순회하면서 blur와 sharp 이미지 쌍을 생성합니다.\n",
    "        for folder_name in os.listdir(self.root_dir):\n",
    "            folder_path = os.path.join(self.root_dir, folder_name)\n",
    "            blur_dir = os.path.join(folder_path, \"blur\")\n",
    "            sharp_dir = os.path.join(folder_path, \"sharp\")\n",
    "            \n",
    "            if not (os.path.isdir(blur_dir) and os.path.isdir(sharp_dir)):\n",
    "                continue\n",
    "            \n",
    "            # blur와 sharp 디렉토리에서 동일한 파일 이름을 가진 이미지 쌍을 찾습니다.\n",
    "            for image_name in os.listdir(blur_dir):\n",
    "                # 유효한 이미지 파일만 선택\n",
    "                if not any(image_name.lower().endswith(ext) for ext in valid_extensions):\n",
    "                    continue\n",
    "                \n",
    "                blur_image_path = os.path.join(blur_dir, image_name)\n",
    "                sharp_image_path = os.path.join(sharp_dir, image_name)\n",
    "                \n",
    "                # 두 파일 모두 존재할 때만 추가\n",
    "                if os.path.isfile(blur_image_path) and os.path.isfile(sharp_image_path):\n",
    "                    pairs.append((blur_image_path, sharp_image_path))\n",
    "        \n",
    "        return pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        blur_image_path, sharp_image_path = self.pairs[idx]\n",
    "        blur_image = Image.open(blur_image_path).convert(\"RGB\")\n",
    "        sharp_image = Image.open(sharp_image_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            blur_image = self.transform(blur_image)\n",
    "            sharp_image = self.transform(sharp_image)\n",
    "        \n",
    "        return blur_image, sharp_image  # (blurred input, sharp target)\n",
    "\n",
    "# 이미지 중앙 부분 crop\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop((512, 512)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 데이터셋 및 데이터 로더\n",
    "train_data = PairedImageDataset(\"../images/GOPRO/train\", transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# Test 데이터셋과 DataLoader 생성\n",
    "# test_dataset = PairedImageDataset(\"../images/GOPRO/test\", transform=transform)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(x, old_range=(-1, 1), new_range=(0, 1), clamp=False):\n",
    "    old_min, old_max = old_range\n",
    "    new_min, new_max = new_range \n",
    "\n",
    "    # rescale x from old_range to new_range\n",
    "    x = (x - old_min) * (new_max - new_min) / (old_max - old_min) + new_min\n",
    "    if clamp:\n",
    "        x = torch.clamp(x, min=new_min, max=new_max)  # 값이 new_min과 new_max 사이에 있도록 클램핑\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 512\n",
    "HEIGHT = 512\n",
    "LATENTS_WIDTH = WIDTH // 8\n",
    "LATENTS_HEIGHT = HEIGHT // 8\n",
    "\n",
    "class LDMFineTuner:\n",
    "    def __init__(self, models, tokenizer, device, log_dir=\"runs/ldm_finetune\", save_path=\"./checkpoints\"):\n",
    "        self.models = models\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.clip = models['clip'].to(device)\n",
    "        self.diffusion = models['diffusion'].to(device)\n",
    "        self.encoder = models['encoder'].to(device)\n",
    "        self.decoder = models['decoder'].to(device)\n",
    "        \n",
    "        # 옵티마이저 설정 (Diffusion 모델만 학습)\n",
    "        self.optimizer = SGD(self.diffusion.parameters(), lr=1e-5)\n",
    "        \n",
    "        self.sampler = DDPMSampler(generator=torch.Generator(device=device))\n",
    "        self.sampler.set_inference_timesteps(num_inference_steps=1000) \n",
    "\n",
    "        # TensorBoard writer 설정\n",
    "        self.writer = SummaryWriter(log_dir=log_dir)\n",
    "        \n",
    "        # 모델과 옵티마이저 저장 경로 설정\n",
    "        self.save_path = save_path\n",
    "        os.makedirs(self.save_path, exist_ok=True)  # 디렉토리 생성\n",
    "\n",
    "\n",
    "    def prepare_batch(self, batch):\n",
    "        blur_images, sharp_images = batch\n",
    "        blur_images = blur_images.to(self.device)\n",
    "        sharp_images = sharp_images.to(self.device)\n",
    "\n",
    "        # 블러 이미지와 선명한 이미지에 대한 다운샘플링된 노이즈 생성\n",
    "        batch_size, _, height, width = blur_images.size()\n",
    "        noise_height, noise_width = height // 8, width // 8  # 다운샘플링 크기에 맞게 설정\n",
    "        noise_for_blur = torch.randn(batch_size, 4, noise_height, noise_width, device=self.device)\n",
    "        noise_for_sharp = torch.randn(batch_size, 4, noise_height, noise_width, device=self.device)\n",
    "\n",
    "        # 블러 이미지를 latent space로 인코딩\n",
    "        with torch.no_grad():\n",
    "            blur_latents = self.encoder(blur_images, noise_for_blur)\n",
    "            sharp_latents = self.encoder(sharp_images, noise_for_sharp)  # Target latents for deblurring\n",
    "        \n",
    "        # CLIP을 사용하여 텍스트 임베딩 생성 (기본 프롬프트 사용)\n",
    "        # 여기서는 임의의 \"Deblur image\" 프롬프트를 사용하여 context 생성\n",
    "        tokens = self.tokenizer([\"Deblur image\"] * blur_images.size(0), \n",
    "                                padding=\"max_length\", max_length=77, \n",
    "                                return_tensors=\"pt\").input_ids.to(self.device)\n",
    "        context = self.clip(tokens)\n",
    "        \n",
    "        return blur_latents, sharp_latents, context\n",
    "    \n",
    "    def train_step(self, blur_latents, sharp_latents, context):\n",
    "        batch_size = blur_latents.shape[0]\n",
    "        \n",
    "        # 랜덤 타임스텝 선택\n",
    "        t = torch.randint(0, self.sampler.num_train_timesteps, (batch_size,), device=self.device).long()\n",
    "        \n",
    "        # 타깃 latents에 노이즈 추가\n",
    "        noise = torch.randn_like(sharp_latents)\n",
    "        # 블러 latent에 노이즈 추가\n",
    "        noisy_latents = self.sampler.add_noise(blur_latents, t)  \n",
    "        \n",
    "        # 시간 임베딩\n",
    "        time_embedding = get_time_embedding(t).to(self.device)\n",
    "        \n",
    "        # Diffusion 모델로 노이즈 예측\n",
    "        predicted_noise = self.diffusion(noisy_latents, context, time_embedding)\n",
    "        \n",
    "        # 손실 계산 (예측된 노이즈와 실제 노이즈 간의 차이)\n",
    "        loss = torch.nn.functional.mse_loss(predicted_noise, noise)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def save_model(self, epoch):\n",
    "        # 모델과 옵티마이저 상태를 지정된 경로에 저장\n",
    "        model_path = os.path.join(self.save_path, f\"model_epoch_{epoch}.pth\")\n",
    "        optimizer_path = os.path.join(self.save_path, f\"optimizer_epoch_{epoch}.pth\")\n",
    "        \n",
    "        torch.save(self.diffusion.state_dict(), model_path)\n",
    "        torch.save(self.optimizer.state_dict(), optimizer_path)\n",
    "        \n",
    "        print(f\"Model and optimizer saved at epoch {epoch} in {self.save_path}\")\n",
    "\n",
    "\n",
    "    def train(self, dataloader, num_epochs):\n",
    "        global_step = 0  # 전체 학습 과정에서의 스텝 카운터를 추가\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0\n",
    "            for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "                blur_images, sharp_images = batch\n",
    "                blur_latents, sharp_latents, context = self.prepare_batch(batch)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.train_step(blur_latents, sharp_latents, context)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # 미니 배치 손실을 TensorBoard에 기록합니다.\n",
    "                # self.writer.add_scalar(\"Loss/Train_Batch\", loss.item(), global_step)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                # global_step += 1 \n",
    "            \n",
    "            avg_loss = total_loss / len(dataloader)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "            self.writer.add_scalar(\"Loss/Train\", avg_loss, epoch)\n",
    "\n",
    "            # 모델과 옵티마이저 저장\n",
    "            self.save_model(epoch + 1)\n",
    "\n",
    "            # 샘플 블러 이미지를 선택하여 디블러링 성능을 시각화\n",
    "            # sample_blur_image = blur_images[0]  # 첫 번째 이미지 선택\n",
    "            # self.log_generated_images(epoch + 1, sample_blur_image)\n",
    "\n",
    "    # def log_generated_images(self, epoch):\n",
    "    #     # 샘플 blur 이미지 생성 후 deblur 결과 기록\n",
    "    #     with torch.no_grad():\n",
    "    #         # 간단한 샘플 블러 이미지를 생성하고 복원\n",
    "    #         sample_blur_latent = torch.randn(1, 4, LATENTS_HEIGHT, LATENTS_WIDTH, device=self.device)\n",
    "    #         tokens = self.tokenizer([\"Deblur image\"], padding=\"max_length\", max_length=77, return_tensors=\"pt\").input_ids.to(self.device)\n",
    "    #         context = self.clip(tokens)\n",
    "\n",
    "    #         timesteps = reversed(self.sampler.timesteps)\n",
    "    #         for t in timesteps:\n",
    "    #             time_embedding = get_time_embedding(t).to(self.device)\n",
    "    #             predicted_noise = self.diffusion(sample_blur_latent, context, time_embedding)\n",
    "    #             sample_blur_latent = self.sampler.step(t, sample_blur_latent, predicted_noise)\n",
    "            \n",
    "    #         # 디코더로 최종 이미지 생성\n",
    "    #         generated_image = self.decoder(sample_blur_latent)\n",
    "    #         generated_image = rescale(generated_image, (-1, 1), (0, 1)).cpu()  # TensorBoard에 출력할 수 있게 rescale\n",
    "\n",
    "    #         # TensorBoard에 이미지 기록\n",
    "    #         self.writer.add_image(\"Generated/Deblurred_Image\", generated_image.squeeze(), epoch)\n",
    "\n",
    "    def generate_sample(self, prompt, input_image, **kwargs):\n",
    "        return generate(prompt, input_image, models=self.models, tokenizer=self.tokenizer, device=self.device, **kwargs)    \n",
    "    def log_generated_images(self, epoch, blur_image):\n",
    "        # 샘플 블러 이미지를 인자로 받아서 디블러링 결과 생성 및 기록\n",
    "        with torch.no_grad():\n",
    "            # \"Deblur image\" 프롬프트를 사용하여 디블러링 결과 생성\n",
    "            prompt = \"Deblur image\"\n",
    "            uncond_prompt = \"\"  # Also known as negative prompt\n",
    "            do_cfg = True\n",
    "            cfg_scale = 8  # min: 1, max: 14 prompt에 집중하는 정도\n",
    "            strength = 1.0\n",
    "\n",
    "            ## SAMPLER\n",
    "\n",
    "            sampler = \"ddpm\"\n",
    "            num_inference_steps = 50\n",
    "            seed = 42\n",
    "\n",
    "\n",
    "            # # Check if blur_image is a Tensor and preprocess it\n",
    "            # if isinstance(blur_image, torch.Tensor):\n",
    "            #     # Ensure the tensor is in CHW format before conversion\n",
    "            #     blur_image = blur_image.squeeze()  # Remove unnecessary dimensions\n",
    "            #     blur_image = F.to_pil_image(blur_image)  # Convert to PIL image\n",
    "            # generated_image = self.generate_sample(prompt=prompt, input_image=blur_image)\n",
    "            generated_image = pipeline.generate(\n",
    "                prompt=prompt,\n",
    "                uncond_prompt = uncond_prompt,\n",
    "                input_image=blur_image,\n",
    "                strength=strength,\n",
    "                do_cfg=do_cfg,\n",
    "                cfg_scale=cfg_scale,\n",
    "                sampler_name=sampler,\n",
    "                n_inference_steps=num_inference_steps,\n",
    "                seed=seed,\n",
    "                models=model.module,\n",
    "                device=device,\n",
    "                idle_device=\"cpu\",\n",
    "                tokenizer=tokenizer,\n",
    "            )         \n",
    "\n",
    "            # TensorBoard에 기록하기 위한 이미지 스케일 조정\n",
    "            blur_image = rescale(torch.tensor(blur_image), (0, 255), (0, 1)).unsqueeze(0)\n",
    "            generated_image = rescale(torch.tensor(generated_image), (0, 255), (0, 1)).unsqueeze(0)\n",
    "            \n",
    "            # TensorBoard에 디블러링된 이미지 기록\n",
    "            self.writer.add_image(\"Input/Blurred_Image\", blur_image, epoch)\n",
    "            self.writer.add_image(\"Generated/Deblurred_Image\", generated_image, epoch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = \"../images/blur_image.png\"\n",
    "# input_image = Image.open(image_path)\n",
    "\n",
    "# fine_tuner = LDMFineTuner(models, tokenizer, device)\n",
    "# fine_tuner.log_generated_images(1, input_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|          | 0/1423 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 1423/1423 [22:30<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Average Loss: 1.8771\n",
      "Model and optimizer saved at epoch 1 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 1423/1423 [22:43<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Average Loss: 1.8495\n",
      "Model and optimizer saved at epoch 2 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 1423/1423 [23:47<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Average Loss: 1.8207\n",
      "Model and optimizer saved at epoch 3 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 1423/1423 [22:39<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Average Loss: 1.7935\n",
      "Model and optimizer saved at epoch 4 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 1423/1423 [22:32<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Average Loss: 1.7674\n",
      "Model and optimizer saved at epoch 5 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 1423/1423 [22:34<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Average Loss: 1.7406\n",
      "Model and optimizer saved at epoch 6 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 1423/1423 [22:38<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Average Loss: 1.7176\n",
      "Model and optimizer saved at epoch 7 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 1423/1423 [22:35<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Average Loss: 1.6854\n",
      "Model and optimizer saved at epoch 8 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 1423/1423 [22:54<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Average Loss: 1.6530\n",
      "Model and optimizer saved at epoch 9 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 1423/1423 [23:03<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Average Loss: 1.6102\n",
      "Model and optimizer saved at epoch 10 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 1423/1423 [23:03<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Average Loss: 1.5605\n",
      "Model and optimizer saved at epoch 11 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 1423/1423 [23:01<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Average Loss: 1.4976\n",
      "Model and optimizer saved at epoch 12 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 1423/1423 [23:06<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Average Loss: 1.4260\n",
      "Model and optimizer saved at epoch 13 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 1423/1423 [23:13<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Average Loss: 1.3506\n",
      "Model and optimizer saved at epoch 14 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 1423/1423 [23:05<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Average Loss: 1.2909\n",
      "Model and optimizer saved at epoch 15 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 1423/1423 [22:59<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Average Loss: 1.2425\n",
      "Model and optimizer saved at epoch 16 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 1423/1423 [24:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Average Loss: 1.2056\n",
      "Model and optimizer saved at epoch 17 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 1423/1423 [23:01<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Average Loss: 1.1750\n",
      "Model and optimizer saved at epoch 18 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 1423/1423 [23:02<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Average Loss: 1.1570\n",
      "Model and optimizer saved at epoch 19 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 1423/1423 [22:43<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Average Loss: 1.1351\n",
      "Model and optimizer saved at epoch 20 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 1423/1423 [22:29<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Average Loss: 1.1197\n",
      "Model and optimizer saved at epoch 21 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 1423/1423 [22:28<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Average Loss: 1.1109\n",
      "Model and optimizer saved at epoch 22 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 1423/1423 [22:40<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Average Loss: 1.1005\n",
      "Model and optimizer saved at epoch 23 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 1423/1423 [23:03<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Average Loss: 1.0929\n",
      "Model and optimizer saved at epoch 24 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 1423/1423 [23:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Average Loss: 1.0856\n",
      "Model and optimizer saved at epoch 25 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 1423/1423 [23:04<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Average Loss: 1.0817\n",
      "Model and optimizer saved at epoch 26 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 1423/1423 [23:03<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Average Loss: 1.0770\n",
      "Model and optimizer saved at epoch 27 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 1423/1423 [22:57<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Average Loss: 1.0710\n",
      "Model and optimizer saved at epoch 28 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 1423/1423 [23:02<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Average Loss: 1.0655\n",
      "Model and optimizer saved at epoch 29 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 1423/1423 [22:54<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Average Loss: 1.0630\n",
      "Model and optimizer saved at epoch 30 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 1423/1423 [24:08<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Average Loss: 1.0594\n",
      "Model and optimizer saved at epoch 31 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 1423/1423 [23:01<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Average Loss: 1.0562\n",
      "Model and optimizer saved at epoch 32 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 1423/1423 [22:54<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Average Loss: 1.0536\n",
      "Model and optimizer saved at epoch 33 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 1423/1423 [22:57<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Average Loss: 1.0522\n",
      "Model and optimizer saved at epoch 34 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 1423/1423 [23:01<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Average Loss: 1.0497\n",
      "Model and optimizer saved at epoch 35 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 1423/1423 [22:57<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Average Loss: 1.0490\n",
      "Model and optimizer saved at epoch 36 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 1423/1423 [23:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Average Loss: 1.0452\n",
      "Model and optimizer saved at epoch 37 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 1423/1423 [22:58<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Average Loss: 1.0438\n",
      "Model and optimizer saved at epoch 38 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 1423/1423 [22:59<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Average Loss: 1.0417\n",
      "Model and optimizer saved at epoch 39 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 1423/1423 [23:21<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Average Loss: 1.0412\n",
      "Model and optimizer saved at epoch 40 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 1423/1423 [23:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Average Loss: 1.0397\n",
      "Model and optimizer saved at epoch 41 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 1423/1423 [23:10<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Average Loss: 1.0382\n",
      "Model and optimizer saved at epoch 42 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 1423/1423 [23:06<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Average Loss: 1.0374\n",
      "Model and optimizer saved at epoch 43 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 1423/1423 [23:02<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Average Loss: 1.0363\n",
      "Model and optimizer saved at epoch 44 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 1423/1423 [22:51<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Average Loss: 1.0356\n",
      "Model and optimizer saved at epoch 45 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 1423/1423 [23:35<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100, Average Loss: 1.0347\n",
      "Model and optimizer saved at epoch 46 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 1423/1423 [22:34<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100, Average Loss: 1.0331\n",
      "Model and optimizer saved at epoch 47 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 1423/1423 [22:43<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100, Average Loss: 1.0331\n",
      "Model and optimizer saved at epoch 48 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 1423/1423 [22:54<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100, Average Loss: 1.0325\n",
      "Model and optimizer saved at epoch 49 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 1423/1423 [23:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Average Loss: 1.0316\n",
      "Model and optimizer saved at epoch 50 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 1423/1423 [23:04<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Average Loss: 1.0304\n",
      "Model and optimizer saved at epoch 51 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 1423/1423 [23:03<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, Average Loss: 1.0309\n",
      "Model and optimizer saved at epoch 52 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 1423/1423 [23:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100, Average Loss: 1.0299\n",
      "Model and optimizer saved at epoch 53 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 1423/1423 [23:05<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100, Average Loss: 1.0290\n",
      "Model and optimizer saved at epoch 54 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 1423/1423 [23:11<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100, Average Loss: 1.0286\n",
      "Model and optimizer saved at epoch 55 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 1423/1423 [23:04<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Average Loss: 1.0274\n",
      "Model and optimizer saved at epoch 56 in ./checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100:  92%|█████████▏| 1305/1423 [21:18<01:56,  1.01it/s]"
     ]
    }
   ],
   "source": [
    "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
    "\n",
    "# 학습\n",
    "fine_tuner = LDMFineTuner(models, tokenizer, device)\n",
    "fine_tuner.train(train_loader, num_epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
